---
layout: post
title:  "argo work-flow 来提交sark 任务"
date:   2022-03-20 23:26:17 +0800
categories: jekyll update
---

###  argo work-flow 提交spark任务

前景提要：
    最近公司准备将一部分的计算通过spark进行预言，来增加并行计算的能力，目前公司的工作流使用的是argo-workflow 。这里来写两个简单的例子用来说明如何提交任务。

##### spark on k8s 的两种类型
1. 通过spark_submit的客户端来提交给k8s，启动一个driver pod 来控制exec pod 。
2. 通过spark operator 的方式，就是将spark 作为k8s的一个crd，然后通过类似k8s deploy,或者pod的资源编排方式，对spark任务进行编排


 spark_submit: 
    
    [https://spark.apache.org/docs/latest/running-on-kubernetes.html](https://spark.apache.org/docs/latest/running-on-kubernetes.html)

  spark operator 
